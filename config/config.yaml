app_config:
  data:
    data_path: data/train.parquet
    batch_data:
      is_remote: true
      remote_data_id: 1lSKBgYQ6bgV4ARRpeRfPMpLgf1GgyWY8
      download_path: data/downloaded_data.parquet
      batch_mode: false
      batch_size: 100
    num_vars:
      - age
      - pclass
      - sibsp
      - parch
      - fare
      - survived
    cat_vars:
      - sex
      - embarked

  db:
    # db_path: db/results.db
    db_path: sqlite:///results.db
    max_connections: 5

  model:
    hyperparams:
      n_splits: 5
      n_estimators: 100
      max_depth: 10
      random_state: 42
      test_size: 0.2

    artifacts:
      model_path: models/model.pkl

  celery_config:
    broker_url: pyamqp://guest@localhost:5672// # Add this to your .env
    result_backend: redis://localhost:6379
    task_config:
      task_serializer: json
      result_serializer: json
      timezone: UTC
      enable_utc: true
    task_routes:
      app.tasks.email_tasks.*: { queue: email }
      app.tasks.dataprocessing.*: { queue: data }
      app.tasks.periodic_tasks.*: { queue: periodic }

    worker_config:
      worker_prefetch_multiplier: 1
      task_acks_late: true
      worker_max_tasks_per_child: 1000

    beat_config:
      beat_schedule:
        cleanup_old_records:
          task: app.tasks.periodic_tasks.cleanup_old_records
          schedule: 3600
      health_check:
        task: app.tasks.periodic_tasks.health_check
        schedule: 300

    other_config:
      result_expires: 3600
      task_compression: gzip
      result_compression: gzip
