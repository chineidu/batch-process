{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88083606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import re\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import Annotated, Any, Generator, Literal, Type, TypeVar\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "# Visualization\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# NumPy settings\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "# Polars settings\n",
    "pl.Config.set_fmt_str_lengths(1_000)\n",
    "pl.Config.set_tbl_cols(n=1_000)\n",
    "pl.Config.set_tbl_rows(n=200)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b2ad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "\n",
    "custom_theme = Theme({\n",
    "    \"white\": \"#FFFFFF\",  # Bright white\n",
    "    \"info\": \"#00FF00\",  # Bright green\n",
    "    \"warning\": \"#FFD700\",  # Bright gold\n",
    "    \"error\": \"#FF1493\",  # Deep pink\n",
    "    \"success\": \"#00FFFF\",  # Cyan\n",
    "    \"highlight\": \"#FF4500\",  # Orange-red\n",
    "})\n",
    "console = Console(theme=custom_theme)\n",
    "\n",
    "\n",
    "def create_path(path: str | Path) -> None:\n",
    "    \"\"\"\n",
    "    Create parent directories for the given path if they don't exist.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str | Path\n",
    "        The file path for which to create parent directories.\n",
    "\n",
    "    \"\"\"\n",
    "    Path(path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def go_up_from_current_directory(*, go_up: int = 1) -> None:\n",
    "    \"\"\"This is used to up a number of directories.\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    go_up: int, default=1\n",
    "        This indicates the number of times to go back up from the current directory.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import sys\n",
    "\n",
    "    CONST: str = \"../\"\n",
    "    NUM: str = CONST * go_up\n",
    "\n",
    "    # Goto the previous directory\n",
    "    prev_directory = os.path.join(os.path.dirname(__name__), NUM)\n",
    "    # Get the 'absolute path' of the previous directory\n",
    "    abs_path_prev_directory = os.path.abspath(prev_directory)\n",
    "\n",
    "    # Add the path to the System paths\n",
    "    sys.path.insert(0, abs_path_prev_directory)\n",
    "    print(abs_path_prev_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "142ff501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/neidu/Desktop/Projects/Personal/batch-process\n"
     ]
    }
   ],
   "source": [
    "go_up_from_current_directory(go_up=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd58e7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list: list[dict[str, Any]] = [\n",
    "    {\n",
    "        \"personId\": \"7HrlxtF1\",\n",
    "        \"sex\": \"female\",\n",
    "        \"age\": 46.85,\n",
    "        \"pclass\": 2,\n",
    "        \"sibsp\": 4,\n",
    "        \"parch\": 3,\n",
    "        \"fare\": 50.63,\n",
    "        \"embarked\": \"s\",\n",
    "    },\n",
    "    {\n",
    "        \"personId\": \"WTibJ8zz\",\n",
    "        \"sex\": \"female\",\n",
    "        \"age\": 62.98,\n",
    "        \"pclass\": 1,\n",
    "        \"sibsp\": 1,\n",
    "        \"parch\": 1,\n",
    "        \"fare\": 72.75,\n",
    "        \"embarked\": \"q\",\n",
    "    },\n",
    "    {\n",
    "        \"personId\": \"m04N6W5m\",\n",
    "        \"sex\": \"male\",\n",
    "        \"age\": 10.95,\n",
    "        \"pclass\": 3,\n",
    "        \"sibsp\": 0,\n",
    "        \"parch\": 3,\n",
    "        \"fare\": 84.17,\n",
    "        \"embarked\": \"c\",\n",
    "    },\n",
    "    {\n",
    "        \"personId\": \"L30K9l5W\",\n",
    "        \"sex\": \"male\",\n",
    "        \"age\": 3.59,\n",
    "        \"pclass\": 2,\n",
    "        \"sibsp\": 4,\n",
    "        \"parch\": 5,\n",
    "        \"fare\": 181.33,\n",
    "        \"embarked\": \"s\",\n",
    "    },\n",
    "    {\n",
    "        \"personId\": \"3ORYJD9e\",\n",
    "        \"sex\": \"male\",\n",
    "        \"age\": 24.67,\n",
    "        \"pclass\": 2,\n",
    "        \"sibsp\": 3,\n",
    "        \"parch\": 4,\n",
    "        \"fare\": 50.14,\n",
    "        \"embarked\": \"s\",\n",
    "    },\n",
    "    {\n",
    "        \"personId\": \"bgQDaJTj\",\n",
    "        \"sex\": \"male\",\n",
    "        \"age\": 56.34,\n",
    "        \"pclass\": 3,\n",
    "        \"sibsp\": 0,\n",
    "        \"parch\": 0,\n",
    "        \"fare\": 103.77,\n",
    "        \"embarked\": \"c\",\n",
    "    },\n",
    "    {\n",
    "        \"personId\": \"lxPRUYHq\",\n",
    "        \"sex\": \"male\",\n",
    "        \"age\": 35.3,\n",
    "        \"pclass\": 1,\n",
    "        \"sibsp\": 2,\n",
    "        \"parch\": 2,\n",
    "        \"fare\": 136.45,\n",
    "        \"embarked\": \"s\",\n",
    "    },\n",
    "    {\n",
    "        \"personId\": \"apGYfspn\",\n",
    "        \"sex\": \"male\",\n",
    "        \"age\": 54.21,\n",
    "        \"pclass\": 2,\n",
    "        \"sibsp\": 3,\n",
    "        \"parch\": 3,\n",
    "        \"fare\": 99.51,\n",
    "        \"embarked\": \"q\",\n",
    "    },\n",
    "    {\n",
    "        \"personId\": \"HULBK23B\",\n",
    "        \"sex\": \"male\",\n",
    "        \"age\": 23.17,\n",
    "        \"pclass\": 1,\n",
    "        \"sibsp\": 1,\n",
    "        \"parch\": 1,\n",
    "        \"fare\": 184.9,\n",
    "        \"embarked\": \"s\",\n",
    "    },\n",
    "    {\n",
    "        \"personId\": \"NDcmeKIV\",\n",
    "        \"sex\": \"female\",\n",
    "        \"age\": 56.18,\n",
    "        \"pclass\": 2,\n",
    "        \"sibsp\": 0,\n",
    "        \"parch\": 2,\n",
    "        \"fare\": 25.48,\n",
    "        \"embarked\": \"q\",\n",
    "    },\n",
    "    {\n",
    "        \"personId\": \"Fa4MXeaS\",\n",
    "        \"sex\": \"male\",\n",
    "        \"age\": 50.27,\n",
    "        \"pclass\": 2,\n",
    "        \"sibsp\": 1,\n",
    "        \"parch\": 2,\n",
    "        \"fare\": 58.35,\n",
    "        \"embarked\": \"s\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da6479d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'person_id': '7HrlxtF1', 'sex': 'female', 'age': 46.85, 'pclass': 2, 'sibsp': 4, 'parch': 3, 'fare': 50.63, 'embarked': 's', 'survived': 1, 'created_at': datetime.datetime(2025, 7, 20, 13, 13, 28, 161607), 'probability': 0.84}, {'person_id': 'WTibJ8zz', 'sex': 'female', 'age': 62.98, 'pclass': 1, 'sibsp': 1, 'parch': 1, 'fare': 72.75, 'embarked': 'q', 'survived': 1, 'created_at': datetime.datetime(2025, 7, 20, 13, 13, 28, 161628), 'probability': 0.87875}, {'person_id': 'm04N6W5m', 'sex': 'male', 'age': 10.95, 'pclass': 3, 'sibsp': 0, 'parch': 3, 'fare': 84.17, 'embarked': 'c', 'survived': 1, 'created_at': datetime.datetime(2025, 7, 20, 13, 13, 28, 161637), 'probability': 0.5966666666666667}, {'person_id': 'L30K9l5W', 'sex': 'male', 'age': 3.59, 'pclass': 2, 'sibsp': 4, 'parch': 5, 'fare': 181.33, 'embarked': 's', 'survived': 0, 'created_at': datetime.datetime(2025, 7, 20, 13, 13, 28, 161645), 'probability': 0.47}, {'person_id': '3ORYJD9e', 'sex': 'male', 'age': 24.67, 'pclass': 2, 'sibsp': 3, 'parch': 4, 'fare': 50.14, 'embarked': 's', 'survived': 0, 'created_at': datetime.datetime(2025, 7, 20, 13, 13, 28, 161652), 'probability': 0.16143137254901962}, {'person_id': 'bgQDaJTj', 'sex': 'male', 'age': 56.34, 'pclass': 3, 'sibsp': 0, 'parch': 0, 'fare': 103.77, 'embarked': 'c', 'survived': 0, 'created_at': datetime.datetime(2025, 7, 20, 13, 13, 28, 161658), 'probability': 0.26571568627450987}, {'person_id': 'lxPRUYHq', 'sex': 'male', 'age': 35.3, 'pclass': 1, 'sibsp': 2, 'parch': 2, 'fare': 136.45, 'embarked': 's', 'survived': 0, 'created_at': datetime.datetime(2025, 7, 20, 13, 13, 28, 161665), 'probability': 0.3045454545454545}, {'person_id': 'apGYfspn', 'sex': 'male', 'age': 54.21, 'pclass': 2, 'sibsp': 3, 'parch': 3, 'fare': 99.51, 'embarked': 'q', 'survived': 0, 'created_at': datetime.datetime(2025, 7, 20, 13, 13, 28, 161671), 'probability': 0.298}, {'person_id': 'HULBK23B', 'sex': 'male', 'age': 23.17, 'pclass': 1, 'sibsp': 1, 'parch': 1, 'fare': 184.9, 'embarked': 's', 'survived': 0, 'created_at': datetime.datetime(2025, 7, 20, 13, 13, 28, 161678), 'probability': 0.20122727272727275}, {'person_id': 'NDcmeKIV', 'sex': 'female', 'age': 56.18, 'pclass': 2, 'sibsp': 0, 'parch': 2, 'fare': 25.48, 'embarked': 'q', 'survived': 1, 'created_at': datetime.datetime(2025, 7, 20, 13, 13, 28, 161684), 'probability': 0.8434615384615384}, {'person_id': 'Fa4MXeaS', 'sex': 'male', 'age': 50.27, 'pclass': 2, 'sibsp': 1, 'parch': 2, 'fare': 58.35, 'embarked': 's', 'survived': 0, 'created_at': datetime.datetime(2025, 7, 20, 13, 13, 28, 161690), 'probability': 0.10676470588235296}]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'outputs'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'person_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'7HrlxtF1'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'survived'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'probability'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.84</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'status'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'success'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'created_at'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2025-07-20T13:13:28.183729'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'person_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'WTibJ8zz'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'survived'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'probability'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.88</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'status'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'success'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'created_at'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2025-07-20T13:13:28.183753'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'person_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'m04N6W5m'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'survived'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'probability'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'status'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'success'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'created_at'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2025-07-20T13:13:28.183766'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'person_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'L30K9l5W'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'survived'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'probability'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.47</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'status'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'success'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'created_at'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2025-07-20T13:13:28.183778'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'person_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'3ORYJD9e'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'survived'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'probability'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.16</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'status'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'success'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'created_at'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2025-07-20T13:13:28.183790'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'person_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'bgQDaJTj'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'survived'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'probability'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.27</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'status'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'success'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'created_at'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2025-07-20T13:13:28.183801'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'person_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'lxPRUYHq'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'survived'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'probability'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'status'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'success'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'created_at'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2025-07-20T13:13:28.183814'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'person_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'apGYfspn'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'survived'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'probability'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'status'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'success'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'created_at'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2025-07-20T13:13:28.183825'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'person_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'HULBK23B'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'survived'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'probability'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'status'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'success'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'created_at'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2025-07-20T13:13:28.183836'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'person_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'NDcmeKIV'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'survived'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'probability'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.84</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'status'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'success'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'created_at'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2025-07-20T13:13:28.183847'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'data'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'person_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Fa4MXeaS'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'survived'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'probability'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.11</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'status'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'success'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'created_at'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2025-07-20T13:13:28.183858'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'outputs'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'data'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'person_id'\u001b[0m: \u001b[32m'7HrlxtF1'\u001b[0m, \u001b[32m'survived'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'probability'\u001b[0m: \u001b[1;36m0.84\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'status'\u001b[0m: \u001b[32m'success'\u001b[0m,\n",
       "            \u001b[32m'created_at'\u001b[0m: \u001b[32m'2025-07-20T13:13:28.183729'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'data'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'person_id'\u001b[0m: \u001b[32m'WTibJ8zz'\u001b[0m, \u001b[32m'survived'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'probability'\u001b[0m: \u001b[1;36m0.88\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'status'\u001b[0m: \u001b[32m'success'\u001b[0m,\n",
       "            \u001b[32m'created_at'\u001b[0m: \u001b[32m'2025-07-20T13:13:28.183753'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'data'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'person_id'\u001b[0m: \u001b[32m'm04N6W5m'\u001b[0m, \u001b[32m'survived'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'probability'\u001b[0m: \u001b[1;36m0.6\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'status'\u001b[0m: \u001b[32m'success'\u001b[0m,\n",
       "            \u001b[32m'created_at'\u001b[0m: \u001b[32m'2025-07-20T13:13:28.183766'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'data'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'person_id'\u001b[0m: \u001b[32m'L30K9l5W'\u001b[0m, \u001b[32m'survived'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'probability'\u001b[0m: \u001b[1;36m0.47\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'status'\u001b[0m: \u001b[32m'success'\u001b[0m,\n",
       "            \u001b[32m'created_at'\u001b[0m: \u001b[32m'2025-07-20T13:13:28.183778'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'data'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'person_id'\u001b[0m: \u001b[32m'3ORYJD9e'\u001b[0m, \u001b[32m'survived'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'probability'\u001b[0m: \u001b[1;36m0.16\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'status'\u001b[0m: \u001b[32m'success'\u001b[0m,\n",
       "            \u001b[32m'created_at'\u001b[0m: \u001b[32m'2025-07-20T13:13:28.183790'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'data'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'person_id'\u001b[0m: \u001b[32m'bgQDaJTj'\u001b[0m, \u001b[32m'survived'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'probability'\u001b[0m: \u001b[1;36m0.27\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'status'\u001b[0m: \u001b[32m'success'\u001b[0m,\n",
       "            \u001b[32m'created_at'\u001b[0m: \u001b[32m'2025-07-20T13:13:28.183801'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'data'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'person_id'\u001b[0m: \u001b[32m'lxPRUYHq'\u001b[0m, \u001b[32m'survived'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'probability'\u001b[0m: \u001b[1;36m0.3\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'status'\u001b[0m: \u001b[32m'success'\u001b[0m,\n",
       "            \u001b[32m'created_at'\u001b[0m: \u001b[32m'2025-07-20T13:13:28.183814'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'data'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'person_id'\u001b[0m: \u001b[32m'apGYfspn'\u001b[0m, \u001b[32m'survived'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'probability'\u001b[0m: \u001b[1;36m0.3\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'status'\u001b[0m: \u001b[32m'success'\u001b[0m,\n",
       "            \u001b[32m'created_at'\u001b[0m: \u001b[32m'2025-07-20T13:13:28.183825'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'data'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'person_id'\u001b[0m: \u001b[32m'HULBK23B'\u001b[0m, \u001b[32m'survived'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'probability'\u001b[0m: \u001b[1;36m0.2\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'status'\u001b[0m: \u001b[32m'success'\u001b[0m,\n",
       "            \u001b[32m'created_at'\u001b[0m: \u001b[32m'2025-07-20T13:13:28.183836'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'data'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'person_id'\u001b[0m: \u001b[32m'NDcmeKIV'\u001b[0m, \u001b[32m'survived'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'probability'\u001b[0m: \u001b[1;36m0.84\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'status'\u001b[0m: \u001b[32m'success'\u001b[0m,\n",
       "            \u001b[32m'created_at'\u001b[0m: \u001b[32m'2025-07-20T13:13:28.183847'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'data'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'person_id'\u001b[0m: \u001b[32m'Fa4MXeaS'\u001b[0m, \u001b[32m'survived'\u001b[0m: \u001b[1;36m0\u001b[0m, \u001b[32m'probability'\u001b[0m: \u001b[1;36m0.11\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'status'\u001b[0m: \u001b[32m'success'\u001b[0m,\n",
       "            \u001b[32m'created_at'\u001b[0m: \u001b[32m'2025-07-20T13:13:28.183858'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.ml.utils import BaseMLTask, get_batch_prediction\n",
    "from src.schemas import MultiPersonsSchema\n",
    "\n",
    "model_dict: dict[str, Any] = BaseMLTask().model_dict\n",
    "records: MultiPersonsSchema = MultiPersonsSchema(persons=data_list)\n",
    "\n",
    "results: Any = get_batch_prediction(records, model_dict)\n",
    "console.print(results.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fe080b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a36e20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace37a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4d1613f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'personId': 'WPtKDQbFvI', 'sex': 'male', 'age': 56.8, 'pclass': 1, 'sibsp': 0, 'parch': 0, 'fare': 265.37, 'embarked': 'q'}, {'personId': '6BZn0feSGA', 'sex': 'male', 'age': 13.73, 'pclass': 1, 'sibsp': 3, 'parch': 1, 'fare': 281.15, 'embarked': 's'}]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "# Define a function to generate a random id\n",
    "def generate_random_id(length: int = 10) -> str:\n",
    "    \"\"\"\n",
    "    Generate a random id string of a given length.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    length : int, optional\n",
    "        Length of the id string to generate. Defaults to 8.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        A random id string of the given length.\n",
    "    \"\"\"\n",
    "    return \"\".join(random.choices(string.ascii_letters + string.digits, k=length))\n",
    "\n",
    "\n",
    "# Define a function to generate a list of random person data\n",
    "def generate_person_data(num_entries: int) -> list[dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Generate a list of random person data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_entries : int\n",
    "        Number of person data entries to generate.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    person_data : list[dict]\n",
    "        List of dictionaries, each containing person data.\n",
    "    \"\"\"\n",
    "    sex_options: list[Literal[\"male\", \"female\"]] = [\"male\", \"female\"]\n",
    "    embarked_options: list[Literal[\"s\", \"c\", \"q\"]] = [\"s\", \"c\", \"q\"]\n",
    "\n",
    "    person_data = []\n",
    "\n",
    "    for _ in range(num_entries):\n",
    "        person = {\n",
    "            \"personId\": generate_random_id(),\n",
    "            \"sex\": random.choice(sex_options),\n",
    "            \"age\": round(random.uniform(0.8, 80.0), 2),\n",
    "            \"pclass\": random.randint(1, 3),\n",
    "            \"sibsp\": random.randint(0, 5),\n",
    "            \"parch\": random.randint(0, 5),\n",
    "            \"fare\": round(random.uniform(5.0, 300.0), 2),\n",
    "            \"embarked\": random.choice(embarked_options),\n",
    "        }\n",
    "        person_data.append(person)\n",
    "\n",
    "    return person_data\n",
    "\n",
    "\n",
    "# Generate a list of 10 random person data entries\n",
    "person_data_list = generate_person_data(150_000)\n",
    "print(person_data_list[:2])\n",
    "\n",
    "\n",
    "def save_json_data(filepath: str, data_format: Literal[\"json\", \"jsonl\"]) -> None:\n",
    "    \"\"\"\n",
    "    Saves a list of dictionaries to a file in either JSON or JSONL format.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath : str\n",
    "        The path to the file to be written\n",
    "    data_format : Literal[\"json\", \"jsonl\"]\n",
    "        If \"json\", the data is written as a single JSON object.\n",
    "        If \"jsonl\", the data is written as a series of newline-separated JSON objects.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    if data_format == \"json\":\n",
    "        with open(filepath, \"w\") as f:\n",
    "            json.dump(person_data_list, fp=f)\n",
    "        return\n",
    "    if data_format == \"json\":\n",
    "        with open(filepath, \"w\") as f:\n",
    "            for person in person_data_list:\n",
    "                f.write(json.dumps(person) + \"\\n\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6183a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp: str = \"../data/sample_data.json\"\n",
    "\n",
    "save_json_data(fp, data_format=\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fed69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "livenessProbe:\n",
    "  exec:\n",
    "    command:\n",
    "      - rabbitmq-diagnostics\n",
    "      - check_port_connectivity\n",
    "  initialDelaySeconds: 60\n",
    "  periodSeconds: 30\n",
    "  timeoutSeconds: 10\n",
    "  failureThreshold: 5\n",
    "  successThreshold: 1\n",
    "\n",
    "readinessProbe:\n",
    "  exec:\n",
    "    command:\n",
    "      - rabbitmq-diagnostics\n",
    "      - ping\n",
    "  initialDelaySeconds: 20\n",
    "  periodSeconds: 10\n",
    "  timeoutSeconds: 5\n",
    "  failureThreshold: 3\n",
    "  successThreshold: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cba7aae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc6e0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import delete, insert, select, update\n",
    "\n",
    "from schemas import EmailSchema\n",
    "from src.database.db_models import EmailLog, get_db_session, init_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365a6092",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72537b8c",
   "metadata": {},
   "source": [
    "## [Docs](https://docs.sqlalchemy.org/en/20/orm/queryguide/select.html)\n",
    "\n",
    "### [Insert](https://docs.sqlalchemy.org/en/20/orm/queryguide/dml.html#orm-bulk-insert-statements)\n",
    "\n",
    "- Old API\n",
    "\n",
    "```python\n",
    "with get_db_session() as session:\n",
    "    data_dict = input_data.model_dump()\n",
    "    record = EmailLog(**data_dict)\n",
    "    session.add(record)\n",
    "    session.flush()\n",
    "    output_data = {key: getattr(record, key) for key in record.output_fields()}\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "- New API\n",
    "\n",
    "```py\n",
    "with get_db_session() as session:\n",
    "    data_dict = input_data.model_dump()\n",
    "    session.execute(insert(EmailLog), [data_dict])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ba0d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data: EmailSchema = EmailSchema(\n",
    "    recipient=\"marketing@client.com\",\n",
    "    subject=\"Partnership Proposal\",\n",
    "    body=\"We would like to discuss a potential partnership opportunity.\",\n",
    ")\n",
    "console.print(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd2a130",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346f439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_db_session() as session:\n",
    "    data_dict = input_data.model_dump()\n",
    "    record = EmailLog(**data_dict)\n",
    "    session.add(record)\n",
    "    session.flush()\n",
    "    output_data = {key: getattr(record, key) for key in record.output_fields()}\n",
    "\n",
    "\n",
    "console.print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236cf44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_db_session() as session:\n",
    "    statement = session.query(EmailLog).where(EmailLog.created_at < datetime.now())\n",
    "    record = session.execute(statement).scalar_one()\n",
    "    output_data = {key: getattr(record, key) for key in record.output_fields()}\n",
    "\n",
    "\n",
    "console.print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f60984",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_2: EmailSchema = EmailSchema(\n",
    "    recipient=\"emeka2@example.com\",\n",
    "    subject=\"test!!!\",\n",
    "    body=\"this is an example body\",\n",
    "    status=\"processing\",\n",
    ")\n",
    "input_data_3: EmailSchema = EmailSchema(\n",
    "    recipient=\"john.doe@example.com\",\n",
    "    subject=\"Meeting Reminder\",\n",
    "    body=\"Hi John, just a reminder about our meeting tomorrow at 10 AM.\",\n",
    "    status=\"processing\",\n",
    ")\n",
    "input_data_4: EmailSchema = EmailSchema(\n",
    "    recipient=\"info@company.org\",\n",
    "    subject=\"New Product Launch\",\n",
    "    body=\"Dear valued customer, check out our exciting new product!\",\n",
    "    status=\"sent\",\n",
    "    created_at=datetime(2025, 7, 10, 9, 0, 0),\n",
    "    sent_at=\"2025-07-10T09:05:00\",\n",
    ")\n",
    "console.print((input_data_2, input_data_3, input_data_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7321d8cd",
   "metadata": {},
   "source": [
    "### [Bulk Insert](https://docs.sqlalchemy.org/en/20/orm/queryguide/dml.html#orm-bulk-insert-statements)\n",
    "\n",
    "- Old API\n",
    "\n",
    "```py\n",
    "with get_db_session() as session:\n",
    "    data_list: list[dict[str, Any]] = [_data.to_data_model_dict() for _data in (input_data_2, input_data_3, input_data_4)]\n",
    "    session.bulk_insert_mappings(EmailLog, data_list)\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "- New API\n",
    "\n",
    "```py\n",
    "with get_db_session() as session:\n",
    "    data_list: list[dict[str, Any]] = [\n",
    "        _data.to_data_model_dict()\n",
    "        for _data in (input_data_2, input_data_3, input_data_4)\n",
    "    ]\n",
    "    session.execute(insert(EmailLog), data_list)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a43ded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_db_session() as session:\n",
    "    data_list: list[dict[str, Any]] = [_data.model_dump() for _data in (input_data_2, input_data_3, input_data_4)]\n",
    "    session.execute(insert(EmailLog), data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81030c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32dc5d45",
   "metadata": {},
   "source": [
    "### Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab00eaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a single record\n",
    "with get_db_session() as session:\n",
    "    statement = select(EmailLog).where(EmailLog.id == 1, EmailLog.status == \"pending\")\n",
    "    record = session.execute(statement).scalar_one()\n",
    "    output_data = {key: getattr(record, key) for key in record.output_fields()}\n",
    "\n",
    "\n",
    "console.print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7778e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all records\n",
    "with get_db_session() as session:\n",
    "    statement = select(EmailLog)\n",
    "    record = session.execute(statement).scalars()\n",
    "\n",
    "    output_data = [{key: getattr(row, key) for key in row.output_fields()} for row in record]\n",
    "\n",
    "console.print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f2e6ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "123d4da2",
   "metadata": {},
   "source": [
    "### [Update](https://docs.sqlalchemy.org/en/20/orm/queryguide/dml.html#orm-update-and-delete-with-custom-where-criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22335d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_db_session() as session:\n",
    "    statement = (\n",
    "        update(EmailLog)\n",
    "        .where(EmailLog.id == 1)\n",
    "        .values(status=\"sent\", sent_at=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    )\n",
    "    # It closes the session and returns None\n",
    "    session.execute(statement)\n",
    "\n",
    "# Verify that the record was updated\n",
    "with get_db_session() as session:\n",
    "    statement = select(EmailLog)\n",
    "    record = session.execute(statement).scalars()\n",
    "\n",
    "    output_data = [{key: getattr(row, key) for key in row.output_fields()} for row in record]\n",
    "\n",
    "console.print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecabd9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d90f5ae1",
   "metadata": {},
   "source": [
    "### [Delete](https://docs.sqlalchemy.org/en/20/orm/queryguide/dml.html#orm-update-and-delete-with-custom-where-criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf4e0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_db_session() as session:\n",
    "    statement = delete(EmailLog).where(EmailLog.id == 2)\n",
    "    # It closes the session and returns None\n",
    "    session.execute(statement)\n",
    "\n",
    "# Verify that the record was updated\n",
    "with get_db_session() as session:\n",
    "    statement = select(EmailLog)\n",
    "    record = session.execute(statement).scalars()\n",
    "\n",
    "    output_data = [{key: getattr(row, key) for key in row.output_fields()} for row in record]\n",
    "\n",
    "console.print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492ee946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1518f29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import app_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ed233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "beat_dict: dict[str, dict[str, Any]] = dict(app_config.celery_config.beat_config.beat_schedule.model_dump().items())\n",
    "\n",
    "# Add the health_check\n",
    "beat_dict[\"health_check\"] = app_config.celery_config.beat_config.health_check.model_dump()\n",
    "\n",
    "\n",
    "console.print(beat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab2f41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_config.celery_config.beat_config.beat_schedule.model_dump().items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f07da3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2050af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5914d6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Any\n",
    "\n",
    "from pydantic import BaseModel, field_serializer\n",
    "\n",
    "\n",
    "class MyModel(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    role: str\n",
    "    salary: float = 0.0\n",
    "    others: Any | None = None\n",
    "\n",
    "    @field_serializer(\"others\")\n",
    "    def serialize(self, value: Any) -> str:\n",
    "        if isinstance(value, datetime):\n",
    "            return value.isoformat()\n",
    "        return json.dumps(value)\n",
    "\n",
    "\n",
    "def my_func(name: str, **kwargs) -> MyModel:\n",
    "    my_dict = {\"name\": name, **kwargs}\n",
    "    return MyModel(**my_dict)\n",
    "\n",
    "\n",
    "result = my_func(\n",
    "    \"Neidu\",\n",
    "    age=30,\n",
    "    role=\"AI Engineer\",\n",
    "    friend=\"None\",\n",
    "    others=[\"Hi\"],\n",
    "    # others=datetime.now(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7d0dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.model_dump())\n",
    "\n",
    "json.loads(result.model_dump()[\"others\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae5b663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import joblib\n",
    "from celery import chord, current_task, group\n",
    "\n",
    "from schemas import ModelOutput, MultiPersonsSchema, MultiPredOutput, PersonSchema\n",
    "from src import PACKAGE_PATH, create_logger\n",
    "from src.celery import celery_app\n",
    "from src.database import get_db_session\n",
    "from src.database.db_models import BaseTask, MLPredictionJob\n",
    "from src.ml.utils import get_batch_prediction, get_prediction\n",
    "\n",
    "logger = create_logger(name=\"ml_prediction\")\n",
    "\n",
    "\n",
    "@celery_app.task(bind=True, base=BaseTask)\n",
    "def process_prediction_chunk(self, persons_data: list[dict[str, Any]], chunk_id: int) -> dict[str, Any]:  # noqa: ANN001\n",
    "    \"\"\"\n",
    "    Process a chunk of ML predictions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    persons_data : list[dict[str, Any]]\n",
    "        List of person data dictionaries for prediction\n",
    "    chunk_id : int\n",
    "        Unique identifier for this chunk\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, Any]\n",
    "        Dictionary containing chunk processing results and metadata\n",
    "    \"\"\"\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Validate input data\n",
    "        multi_persons = MultiPersonsSchema(persons=persons_data)  # type: ignore\n",
    "        total_items = len(multi_persons.persons)\n",
    "\n",
    "        # Load model once for the entire chunk\n",
    "        model_dict_fp: Path = PACKAGE_PATH / \"models/model.pkl\"\n",
    "        with open(model_dict_fp, \"rb\") as f:\n",
    "            model_dict = joblib.load(f)\n",
    "\n",
    "        # Process predictions\n",
    "        prediction_results = []\n",
    "\n",
    "        for i, person in enumerate(multi_persons.persons):\n",
    "            # Update task progress\n",
    "            current_task.update_state(\n",
    "                state=\"PROGRESS\",\n",
    "                meta={\"current\": i + 1, \"total\": total_items, \"chunk_id\": chunk_id},\n",
    "            )\n",
    "\n",
    "            # Make individual prediction\n",
    "            result: ModelOutput = get_prediction(person, model_dict)\n",
    "            prediction_results.append(result.model_dump())\n",
    "\n",
    "        processing_time = time.time() - start_time\n",
    "\n",
    "        logger.info(f\"Processed chunk {chunk_id} with {total_items} predictions in {processing_time:.2f}s\")\n",
    "\n",
    "        return {\n",
    "            \"chunk_id\": chunk_id,\n",
    "            \"prediction_results\": prediction_results,\n",
    "            \"processing_time\": processing_time,\n",
    "            \"items_count\": total_items,\n",
    "            \"status\": \"success\",\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing prediction chunk {chunk_id}: {e}\")\n",
    "        raise self.retry(exc=e) from e\n",
    "\n",
    "\n",
    "@celery_app.task\n",
    "def combine_prediction_results(chunk_results: list[dict[str, Any]]) -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Combine results from multiple prediction chunks.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    chunk_results : list[dict[str, Any]]\n",
    "        List of chunk processing results\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, Any]\n",
    "        Dictionary containing combined prediction results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with get_db_session() as session:\n",
    "            # Sort chunks by chunk_id\n",
    "            sorted_results = sorted(chunk_results, key=lambda x: x[\"chunk_id\"])\n",
    "\n",
    "            # Combine all prediction results\n",
    "            combined_predictions = []\n",
    "            total_processing_time = 0\n",
    "            total_items = 0\n",
    "\n",
    "            for result in sorted_results:\n",
    "                combined_predictions.extend(result[\"prediction_results\"])\n",
    "                total_processing_time += result[\"processing_time\"]\n",
    "                total_items += result[\"items_count\"]\n",
    "\n",
    "            avg_processing_time = round((total_processing_time / len(sorted_results)), 2)\n",
    "\n",
    "            # Save to database\n",
    "            job_data = {\n",
    "                \"job_name\": \"batch_ml_prediction\",\n",
    "                \"input_data\": json.dumps({\"chunks\": len(sorted_results), \"total_items\": total_items}),\n",
    "                \"output_data\": json.dumps({\"predictions\": combined_predictions}),\n",
    "                \"processing_time\": avg_processing_time,\n",
    "                \"prediction_count\": total_items,\n",
    "                \"status\": \"completed\",\n",
    "                \"completed_at\": datetime.now(),\n",
    "            }\n",
    "\n",
    "            job = MLPredictionJob(**job_data)\n",
    "            session.add(job)\n",
    "            session.flush()\n",
    "\n",
    "            logger.info(f\"Combined {len(sorted_results)} chunks with {total_items} total predictions\")\n",
    "\n",
    "            return {\n",
    "                \"status\": \"completed\",\n",
    "                \"total_chunks\": len(sorted_results),\n",
    "                \"total_predictions\": total_items,\n",
    "                \"avg_processing_time\": avg_processing_time,\n",
    "                \"job_id\": job.id,\n",
    "                \"predictions\": combined_predictions,\n",
    "            }\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error combining prediction results: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "@celery_app.task\n",
    "def process_batch_predictions(persons_data: list[dict[str, Any]], chunk_size: int = 10) -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Process a large batch of ML predictions by splitting into chunks and using chord.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    persons_data : list[dict[str, Any]]\n",
    "        List of person data dictionaries for prediction\n",
    "    chunk_size : int, optional\n",
    "        Size of each processing chunk, by default 10\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, Any]\n",
    "        Dictionary containing batch processing dispatch information\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Split data into chunks\n",
    "        chunks = [persons_data[i : i + chunk_size] for i in range(0, len(persons_data), chunk_size)]\n",
    "\n",
    "        # Create a chord: process chunks in parallel, then combine results\n",
    "        job = chord(\n",
    "            group(process_prediction_chunk.s(chunk, i) for i, chunk in enumerate(chunks)),\n",
    "            combine_prediction_results.s(),\n",
    "        )\n",
    "\n",
    "        result = job.apply_async()\n",
    "\n",
    "        logger.info(f\"Dispatched batch prediction job with {len(persons_data)} items in {len(chunks)} chunks\")\n",
    "\n",
    "        return {\n",
    "            \"status\": \"dispatched\",\n",
    "            \"total_items\": len(persons_data),\n",
    "            \"chunks\": len(chunks),\n",
    "            \"chunk_size\": chunk_size,\n",
    "            \"chord_id\": result.id,\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error dispatching batch predictions: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "@celery_app.task(bind=True, base=BaseTask)\n",
    "def process_dlq_message(self, message_data: dict[str, Any]) -> dict[str, Any]:  # noqa: ANN001\n",
    "    \"\"\"\n",
    "    Process a message from the dead letter queue.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    message_data : dict[str, Any]\n",
    "        Message data from DLQ\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, Any]\n",
    "        Dictionary containing DLQ processing results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate the message data\n",
    "        if \"persons\" in message_data:\n",
    "            # Batch message\n",
    "            record = MultiPersonsSchema(**message_data)\n",
    "            message_type = \"batch\"\n",
    "            item_count = len(record.persons)\n",
    "        else:\n",
    "            # Single message\n",
    "            record = PersonSchema(**message_data)\n",
    "            message_type = \"single\"\n",
    "            item_count = 1\n",
    "\n",
    "        # Log DLQ message to database (you might want to create a DLQ table)\n",
    "        logger.warning(f\"Processing DLQ message: {message_type} with {item_count} items\")\n",
    "\n",
    "        # For now, just log the DLQ data - you can extend this to save to a DLQ table\n",
    "        with get_db_session() as session:\n",
    "            job_data = {\n",
    "                \"job_name\": f\"dlq_{message_type}_processing\",\n",
    "                \"input_data\": json.dumps(message_data),\n",
    "                \"output_data\": json.dumps({\"status\": \"dlq_processed\", \"message_type\": message_type}),\n",
    "                \"processing_time\": 0.0,\n",
    "                \"prediction_count\": 0,\n",
    "                \"status\": \"dlq_processed\",\n",
    "                \"completed_at\": datetime.now(),\n",
    "            }\n",
    "\n",
    "            job = MLPredictionJob(**job_data)\n",
    "            session.add(job)\n",
    "            session.flush()\n",
    "\n",
    "            logger.info(f\"DLQ message processed and logged with job_id: {job.id}\")\n",
    "\n",
    "            return {\n",
    "                \"status\": \"dlq_processed\",\n",
    "                \"message_type\": message_type,\n",
    "                \"item_count\": item_count,\n",
    "                \"job_id\": job.id,\n",
    "            }\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing DLQ message: {e}\")\n",
    "        raise self.retry(exc=e) from e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eaaad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a769141e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "batch-process",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
