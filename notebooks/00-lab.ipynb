{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88083606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import re\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import Annotated, Any, Generator, Literal, Type, TypeVar\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "# Visualization\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# NumPy settings\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "# Polars settings\n",
    "pl.Config.set_fmt_str_lengths(1_000)\n",
    "pl.Config.set_tbl_cols(n=1_000)\n",
    "pl.Config.set_tbl_rows(n=200)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71b2ad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "\n",
    "custom_theme = Theme(\n",
    "    {\n",
    "        \"white\": \"#FFFFFF\",  # Bright white\n",
    "        \"info\": \"#00FF00\",  # Bright green\n",
    "        \"warning\": \"#FFD700\",  # Bright gold\n",
    "        \"error\": \"#FF1493\",  # Deep pink\n",
    "        \"success\": \"#00FFFF\",  # Cyan\n",
    "        \"highlight\": \"#FF4500\",  # Orange-red\n",
    "    }\n",
    ")\n",
    "console = Console(theme=custom_theme)\n",
    "\n",
    "\n",
    "def create_path(path: str | Path) -> None:\n",
    "    \"\"\"\n",
    "    Create parent directories for the given path if they don't exist.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str | Path\n",
    "        The file path for which to create parent directories.\n",
    "\n",
    "    \"\"\"\n",
    "    Path(path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def go_up_from_current_directory(*, go_up: int = 1) -> None:\n",
    "    \"\"\"This is used to up a number of directories.\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    go_up: int, default=1\n",
    "        This indicates the number of times to go back up from the current directory.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import sys\n",
    "\n",
    "    CONST: str = \"../\"\n",
    "    NUM: str = CONST * go_up\n",
    "\n",
    "    # Goto the previous directory\n",
    "    prev_directory = os.path.join(os.path.dirname(__name__), NUM)\n",
    "    # Get the 'absolute path' of the previous directory\n",
    "    abs_path_prev_directory = os.path.abspath(prev_directory)\n",
    "\n",
    "    # Add the path to the System paths\n",
    "    sys.path.insert(0, abs_path_prev_directory)\n",
    "    print(abs_path_prev_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "142ff501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mac/Desktop/MyProjects/batch-process\n"
     ]
    }
   ],
   "source": [
    "go_up_from_current_directory(go_up=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1ecde1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AppConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">data</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Data</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">data_path</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'data/train.parquet'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">batch_data</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BatchData</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">is_remote</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">remote_data_id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'1lSKBgYQ6bgV4ARRpeRfPMpLgf1GgyWY8'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">download_path</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'data/downloaded_data.parquet'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">batch_mode</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">batch_size</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">num_vars</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'age'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pclass'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'sibsp'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'parch'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'fare'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'survived'</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">cat_vars</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'sex'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'embarked'</span><span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">db</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">DB</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">db_path</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'sqlite:///results.db'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">max_connections</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Model</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">hyperparams</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ModelHyperparams</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">n_splits</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #808000; text-decoration-color: #808000\">n_estimators</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #808000; text-decoration-color: #808000\">max_depth</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #808000; text-decoration-color: #808000\">random_state</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>, <span style=\"color: #808000; text-decoration-color: #808000\">test_size</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">artifacts</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Artifacts</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">model_path</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'models/model.pkl'</span><span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">celery_config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CeleryConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">task_config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TaskConfig</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">task_serializer</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'json'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">result_serializer</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'json'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">timezone</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'UTC'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">enable_utc</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">task_routes</span>=<span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'src.celery_pkg.tasks.email_tasks.*'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">QueueConfig</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">queue</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'email'</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'src.celery_pkg.tasks.data_processing.*'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">QueueConfig</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">queue</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'data'</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'src.celery_pkg.tasks.periodic_tasks.*'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">QueueConfig</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">queue</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'periodic'</span><span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'src.celery_pkg.tasks.ml_prediction_tasks.*'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">QueueConfig</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">queue</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'predict'</span><span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">worker_config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">WorkerConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">worker_prefetch_multiplier</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">task_acks_late</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">worker_max_tasks_per_child</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">beat_config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BeatConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">beat_schedule</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">BeatSchedule</span><span style=\"font-weight: bold\">(</span>\n",
       "                <span style=\"color: #808000; text-decoration-color: #808000\">cleanup_old_records</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TaskAndSchedule</span><span style=\"font-weight: bold\">(</span>\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">task</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'src.celery_pkg.tasks.periodic_tasks.cleanup_old_records'</span>,\n",
       "                    <span style=\"color: #808000; text-decoration-color: #808000\">schedule</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3600</span>\n",
       "                <span style=\"font-weight: bold\">)</span>\n",
       "            <span style=\"font-weight: bold\">)</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">health_check</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TaskAndSchedule</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">task</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'src.celery_pkg.tasks.periodic_tasks.health_check'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">schedule</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">180</span><span style=\"font-weight: bold\">)</span>\n",
       "        <span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">other_config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">OtherConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">result_expires</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3600</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">task_compression</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gzip'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">result_compression</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gzip'</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">result_backend_always_retry</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">result_persistent</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">result_backend_max_retries</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">api_config</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">APIConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">title</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Data Processing API'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Data Processing API'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">description</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'API for processing large datasets'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">version</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'v0.2.5'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">status</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'healthy'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">batch_size</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">prefix</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'/api/v1'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">server</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Server</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">host</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'0.0.0.0'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">port</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8000</span>, <span style=\"color: #808000; text-decoration-color: #808000\">workers</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">reload</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">middleware</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Middleware</span><span style=\"font-weight: bold\">(</span>\n",
       "            <span style=\"color: #808000; text-decoration-color: #808000\">cors</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CORS</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">allow_origins</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'*'</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">allow_credentials</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">allow_methods</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'*'</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">allow_headers</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'*'</span><span style=\"font-weight: bold\">])</span>\n",
       "        <span style=\"font-weight: bold\">)</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mAppConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mdata\u001b[0m=\u001b[1;35mData\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mdata_path\u001b[0m=\u001b[32m'data/train.parquet'\u001b[0m,\n",
       "        \u001b[33mbatch_data\u001b[0m=\u001b[1;35mBatchData\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mis_remote\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[33mremote_data_id\u001b[0m=\u001b[32m'1lSKBgYQ6bgV4ARRpeRfPMpLgf1GgyWY8'\u001b[0m,\n",
       "            \u001b[33mdownload_path\u001b[0m=\u001b[32m'data/downloaded_data.parquet'\u001b[0m,\n",
       "            \u001b[33mbatch_mode\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
       "            \u001b[33mbatch_size\u001b[0m=\u001b[1;36m100\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[33mnum_vars\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'age'\u001b[0m, \u001b[32m'pclass'\u001b[0m, \u001b[32m'sibsp'\u001b[0m, \u001b[32m'parch'\u001b[0m, \u001b[32m'fare'\u001b[0m, \u001b[32m'survived'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[33mcat_vars\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'sex'\u001b[0m, \u001b[32m'embarked'\u001b[0m\u001b[1m]\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mdb\u001b[0m=\u001b[1;35mDB\u001b[0m\u001b[1m(\u001b[0m\u001b[33mdb_path\u001b[0m=\u001b[32m'sqlite:///results.db'\u001b[0m, \u001b[33mmax_connections\u001b[0m=\u001b[1;36m5\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[33mmodel\u001b[0m=\u001b[1;35mModel\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mhyperparams\u001b[0m=\u001b[1;35mModelHyperparams\u001b[0m\u001b[1m(\u001b[0m\u001b[33mn_splits\u001b[0m=\u001b[1;36m5\u001b[0m, \u001b[33mn_estimators\u001b[0m=\u001b[1;36m100\u001b[0m, \u001b[33mmax_depth\u001b[0m=\u001b[1;36m10\u001b[0m, \u001b[33mrandom_state\u001b[0m=\u001b[1;36m42\u001b[0m, \u001b[33mtest_size\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[33martifacts\u001b[0m=\u001b[1;35mArtifacts\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmodel_path\u001b[0m=\u001b[32m'models/model.pkl'\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mcelery_config\u001b[0m=\u001b[1;35mCeleryConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mtask_config\u001b[0m=\u001b[1;35mTaskConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mtask_serializer\u001b[0m=\u001b[32m'json'\u001b[0m, \u001b[33mresult_serializer\u001b[0m=\u001b[32m'json'\u001b[0m, \u001b[33mtimezone\u001b[0m=\u001b[32m'UTC'\u001b[0m, \u001b[33menable_utc\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[33mtask_routes\u001b[0m=\u001b[1m{\u001b[0m\n",
       "            \u001b[32m'src.celery_pkg.tasks.email_tasks.*'\u001b[0m: \u001b[1;35mQueueConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mqueue\u001b[0m=\u001b[32m'email'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[32m'src.celery_pkg.tasks.data_processing.*'\u001b[0m: \u001b[1;35mQueueConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mqueue\u001b[0m=\u001b[32m'data'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[32m'src.celery_pkg.tasks.periodic_tasks.*'\u001b[0m: \u001b[1;35mQueueConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mqueue\u001b[0m=\u001b[32m'periodic'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "            \u001b[32m'src.celery_pkg.tasks.ml_prediction_tasks.*'\u001b[0m: \u001b[1;35mQueueConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mqueue\u001b[0m=\u001b[32m'predict'\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[33mworker_config\u001b[0m=\u001b[1;35mWorkerConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mworker_prefetch_multiplier\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
       "            \u001b[33mtask_acks_late\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[33mworker_max_tasks_per_child\u001b[0m=\u001b[1;36m1000\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[33mbeat_config\u001b[0m=\u001b[1;35mBeatConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mbeat_schedule\u001b[0m=\u001b[1;35mBeatSchedule\u001b[0m\u001b[1m(\u001b[0m\n",
       "                \u001b[33mcleanup_old_records\u001b[0m=\u001b[1;35mTaskAndSchedule\u001b[0m\u001b[1m(\u001b[0m\n",
       "                    \u001b[33mtask\u001b[0m=\u001b[32m'src.celery_pkg.tasks.periodic_tasks.cleanup_old_records'\u001b[0m,\n",
       "                    \u001b[33mschedule\u001b[0m=\u001b[1;36m3600\u001b[0m\n",
       "                \u001b[1m)\u001b[0m\n",
       "            \u001b[1m)\u001b[0m,\n",
       "            \u001b[33mhealth_check\u001b[0m=\u001b[1;35mTaskAndSchedule\u001b[0m\u001b[1m(\u001b[0m\u001b[33mtask\u001b[0m=\u001b[32m'src.celery_pkg.tasks.periodic_tasks.health_check'\u001b[0m, \u001b[33mschedule\u001b[0m=\u001b[1;36m180\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m,\n",
       "        \u001b[33mother_config\u001b[0m=\u001b[1;35mOtherConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mresult_expires\u001b[0m=\u001b[1;36m3600\u001b[0m,\n",
       "            \u001b[33mtask_compression\u001b[0m=\u001b[32m'gzip'\u001b[0m,\n",
       "            \u001b[33mresult_compression\u001b[0m=\u001b[32m'gzip'\u001b[0m,\n",
       "            \u001b[33mresult_backend_always_retry\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[33mresult_persistent\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "            \u001b[33mresult_backend_max_retries\u001b[0m=\u001b[1;36m3\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[33mapi_config\u001b[0m=\u001b[1;35mAPIConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mtitle\u001b[0m=\u001b[32m'Data Processing API'\u001b[0m,\n",
       "        \u001b[33mname\u001b[0m=\u001b[32m'Data Processing API'\u001b[0m,\n",
       "        \u001b[33mdescription\u001b[0m=\u001b[32m'API for processing large datasets'\u001b[0m,\n",
       "        \u001b[33mversion\u001b[0m=\u001b[32m'v0.2.5'\u001b[0m,\n",
       "        \u001b[33mstatus\u001b[0m=\u001b[32m'healthy'\u001b[0m,\n",
       "        \u001b[33mbatch_size\u001b[0m=\u001b[1;36m5\u001b[0m,\n",
       "        \u001b[33mprefix\u001b[0m=\u001b[32m'/api/v1'\u001b[0m,\n",
       "        \u001b[33mserver\u001b[0m=\u001b[1;35mServer\u001b[0m\u001b[1m(\u001b[0m\u001b[33mhost\u001b[0m=\u001b[32m'0.0.0.0'\u001b[0m, \u001b[33mport\u001b[0m=\u001b[1;36m8000\u001b[0m, \u001b[33mworkers\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mreload\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m,\n",
       "        \u001b[33mmiddleware\u001b[0m=\u001b[1;35mMiddleware\u001b[0m\u001b[1m(\u001b[0m\n",
       "            \u001b[33mcors\u001b[0m=\u001b[1;35mCORS\u001b[0m\u001b[1m(\u001b[0m\u001b[33mallow_origins\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'*'\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mallow_credentials\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mallow_methods\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'*'\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mallow_headers\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'*'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "        \u001b[1m)\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.config import app_config\n",
    "\n",
    "console.print(app_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2068ded2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace37a4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d1613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "# Define a function to generate a random id\n",
    "def generate_random_id(length: int = 8) -> str:\n",
    "    \"\"\"\n",
    "    Generate a random id string of a given length.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    length : int, optional\n",
    "        Length of the id string to generate. Defaults to 8.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        A random id string of the given length.\n",
    "    \"\"\"\n",
    "    return \"\".join(random.choices(string.ascii_letters + string.digits, k=length))\n",
    "\n",
    "\n",
    "# Define a function to generate a list of random person data\n",
    "def generate_person_data(num_entries: int) -> list[dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Generate a list of random person data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_entries : int\n",
    "        Number of person data entries to generate.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    person_data : list[dict]\n",
    "        List of dictionaries, each containing person data.\n",
    "    \"\"\"\n",
    "    sex_options: list[Literal[\"male\", \"female\"]] = [\"male\", \"female\"]\n",
    "    embarked_options: list[Literal[\"s\", \"c\", \"q\"]] = [\"s\", \"c\", \"q\"]\n",
    "\n",
    "    person_data = []\n",
    "\n",
    "    for _ in range(num_entries):\n",
    "        person = {\n",
    "            \"personId\": generate_random_id(),\n",
    "            \"sex\": random.choice(sex_options),\n",
    "            \"age\": round(random.uniform(0.5, 80.0), 2),\n",
    "            \"pclass\": random.randint(1, 3),\n",
    "            \"sibsp\": random.randint(0, 5),\n",
    "            \"parch\": random.randint(0, 5),\n",
    "            \"fare\": round(random.uniform(5.0, 200.0), 2),\n",
    "            \"embarked\": random.choice(embarked_options),\n",
    "        }\n",
    "        person_data.append(person)\n",
    "\n",
    "    return person_data\n",
    "\n",
    "\n",
    "# Generate a list of 10 random person data entries\n",
    "person_data_list = generate_person_data(10)\n",
    "print(person_data_list)\n",
    "\n",
    "fp: str = \"./data/sample_data.jsonl\"\n",
    "\n",
    "with open(fp, \"w\") as f:\n",
    "    for person in person_data_list:\n",
    "        f.write(json.dumps(person) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cba7aae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc6e0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import delete, insert, select, update\n",
    "\n",
    "from schemas import EmailSchema\n",
    "from src.database.db_models import EmailLog, get_db_session, init_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365a6092",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72537b8c",
   "metadata": {},
   "source": [
    "## [Docs](https://docs.sqlalchemy.org/en/20/orm/queryguide/select.html)\n",
    "\n",
    "### [Insert](https://docs.sqlalchemy.org/en/20/orm/queryguide/dml.html#orm-bulk-insert-statements)\n",
    "\n",
    "- Old API\n",
    "\n",
    "```python\n",
    "with get_db_session() as session:\n",
    "    data_dict = input_data.model_dump()\n",
    "    record = EmailLog(**data_dict)\n",
    "    session.add(record)\n",
    "    session.flush()\n",
    "    output_data = {key: getattr(record, key) for key in record.output_fields()}\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "- New API\n",
    "\n",
    "```py\n",
    "with get_db_session() as session:\n",
    "    data_dict = input_data.model_dump()\n",
    "    session.execute(insert(EmailLog), [data_dict])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ba0d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data: EmailSchema = EmailSchema(\n",
    "    recipient=\"marketing@client.com\",\n",
    "    subject=\"Partnership Proposal\",\n",
    "    body=\"We would like to discuss a potential partnership opportunity.\",\n",
    ")\n",
    "console.print(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd2a130",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346f439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_db_session() as session:\n",
    "    data_dict = input_data.model_dump()\n",
    "    record = EmailLog(**data_dict)\n",
    "    session.add(record)\n",
    "    session.flush()\n",
    "    output_data = {key: getattr(record, key) for key in record.output_fields()}\n",
    "\n",
    "\n",
    "console.print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236cf44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_db_session() as session:\n",
    "    statement = session.query(EmailLog).where(EmailLog.created_at < datetime.now())\n",
    "    record = session.execute(statement).scalar_one()\n",
    "    output_data = {key: getattr(record, key) for key in record.output_fields()}\n",
    "\n",
    "\n",
    "console.print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f60984",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_2: EmailSchema = EmailSchema(\n",
    "    recipient=\"emeka2@example.com\",\n",
    "    subject=\"test!!!\",\n",
    "    body=\"this is an example body\",\n",
    "    status=\"processing\",\n",
    ")\n",
    "input_data_3: EmailSchema = EmailSchema(\n",
    "    recipient=\"john.doe@example.com\",\n",
    "    subject=\"Meeting Reminder\",\n",
    "    body=\"Hi John, just a reminder about our meeting tomorrow at 10 AM.\",\n",
    "    status=\"processing\",\n",
    ")\n",
    "input_data_4: EmailSchema = EmailSchema(\n",
    "    recipient=\"info@company.org\",\n",
    "    subject=\"New Product Launch\",\n",
    "    body=\"Dear valued customer, check out our exciting new product!\",\n",
    "    status=\"sent\",\n",
    "    created_at=datetime(2025, 7, 10, 9, 0, 0),\n",
    "    sent_at=\"2025-07-10T09:05:00\",\n",
    ")\n",
    "console.print((input_data_2, input_data_3, input_data_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7321d8cd",
   "metadata": {},
   "source": [
    "### [Bulk Insert](https://docs.sqlalchemy.org/en/20/orm/queryguide/dml.html#orm-bulk-insert-statements)\n",
    "\n",
    "- Old API\n",
    "\n",
    "```py\n",
    "with get_db_session() as session:\n",
    "    data_list: list[dict[str, Any]] = [_data.to_data_model_dict() for _data in (input_data_2, input_data_3, input_data_4)]\n",
    "    session.bulk_insert_mappings(EmailLog, data_list)\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "- New API\n",
    "\n",
    "```py\n",
    "with get_db_session() as session:\n",
    "    data_list: list[dict[str, Any]] = [\n",
    "        _data.to_data_model_dict()\n",
    "        for _data in (input_data_2, input_data_3, input_data_4)\n",
    "    ]\n",
    "    session.execute(insert(EmailLog), data_list)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a43ded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_db_session() as session:\n",
    "    data_list: list[dict[str, Any]] = [_data.model_dump() for _data in (input_data_2, input_data_3, input_data_4)]\n",
    "    session.execute(insert(EmailLog), data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81030c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32dc5d45",
   "metadata": {},
   "source": [
    "### Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab00eaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a single record\n",
    "with get_db_session() as session:\n",
    "    statement = select(EmailLog).where(EmailLog.id == 1, EmailLog.status == \"pending\")\n",
    "    record = session.execute(statement).scalar_one()\n",
    "    output_data = {key: getattr(record, key) for key in record.output_fields()}\n",
    "\n",
    "\n",
    "console.print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7778e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all records\n",
    "with get_db_session() as session:\n",
    "    statement = select(EmailLog)\n",
    "    record = session.execute(statement).scalars()\n",
    "\n",
    "    output_data = [{key: getattr(row, key) for key in row.output_fields()} for row in record]\n",
    "\n",
    "console.print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f2e6ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "123d4da2",
   "metadata": {},
   "source": [
    "### [Update](https://docs.sqlalchemy.org/en/20/orm/queryguide/dml.html#orm-update-and-delete-with-custom-where-criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22335d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_db_session() as session:\n",
    "    statement = (\n",
    "        update(EmailLog)\n",
    "        .where(EmailLog.id == 1)\n",
    "        .values(status=\"sent\", sent_at=datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    )\n",
    "    # It closes the session and returns None\n",
    "    session.execute(statement)\n",
    "\n",
    "# Verify that the record was updated\n",
    "with get_db_session() as session:\n",
    "    statement = select(EmailLog)\n",
    "    record = session.execute(statement).scalars()\n",
    "\n",
    "    output_data = [{key: getattr(row, key) for key in row.output_fields()} for row in record]\n",
    "\n",
    "console.print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecabd9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d90f5ae1",
   "metadata": {},
   "source": [
    "### [Delete](https://docs.sqlalchemy.org/en/20/orm/queryguide/dml.html#orm-update-and-delete-with-custom-where-criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf4e0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_db_session() as session:\n",
    "    statement = delete(EmailLog).where(EmailLog.id == 2)\n",
    "    # It closes the session and returns None\n",
    "    session.execute(statement)\n",
    "\n",
    "# Verify that the record was updated\n",
    "with get_db_session() as session:\n",
    "    statement = select(EmailLog)\n",
    "    record = session.execute(statement).scalars()\n",
    "\n",
    "    output_data = [{key: getattr(row, key) for key in row.output_fields()} for row in record]\n",
    "\n",
    "console.print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492ee946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1518f29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import app_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ed233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "beat_dict: dict[str, dict[str, Any]] = dict(app_config.celery_config.beat_config.beat_schedule.model_dump().items())\n",
    "\n",
    "# Add the health_check\n",
    "beat_dict[\"health_check\"] = app_config.celery_config.beat_config.health_check.model_dump()\n",
    "\n",
    "\n",
    "console.print(beat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab2f41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_config.celery_config.beat_config.beat_schedule.model_dump().items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f07da3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2050af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5914d6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Any\n",
    "\n",
    "from pydantic import BaseModel, field_serializer\n",
    "\n",
    "\n",
    "class MyModel(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    role: str\n",
    "    salary: float = 0.0\n",
    "    others: Any | None = None\n",
    "\n",
    "    @field_serializer(\"others\")\n",
    "    def serialize(self, value: Any) -> str:\n",
    "        if isinstance(value, datetime):\n",
    "            return value.isoformat()\n",
    "        return json.dumps(value)\n",
    "\n",
    "\n",
    "def my_func(name: str, **kwargs) -> MyModel:\n",
    "    my_dict = {\"name\": name, **kwargs}\n",
    "    return MyModel(**my_dict)\n",
    "\n",
    "\n",
    "result = my_func(\n",
    "    \"Neidu\",\n",
    "    age=30,\n",
    "    role=\"AI Engineer\",\n",
    "    friend=\"None\",\n",
    "    others=[\"Hi\"],\n",
    "    # others=datetime.now(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7d0dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.model_dump())\n",
    "\n",
    "json.loads(result.model_dump()[\"others\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae5b663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "import joblib\n",
    "\n",
    "from celery import chord, current_task, group\n",
    "from schemas import ModelOutput, MultiPersonsSchema, MultiPredOutput, PersonSchema\n",
    "from src import PACKAGE_PATH, create_logger\n",
    "from src.celery import celery_app\n",
    "from src.database import get_db_session\n",
    "from src.database.db_models import BaseTask, MLPredictionJob\n",
    "from src.ml.utils import get_batch_prediction, get_prediction\n",
    "\n",
    "logger = create_logger(name=\"ml_prediction\")\n",
    "\n",
    "\n",
    "@celery_app.task(bind=True, base=BaseTask)\n",
    "def process_prediction_chunk(self, persons_data: list[dict[str, Any]], chunk_id: int) -> dict[str, Any]:  # noqa: ANN001\n",
    "    \"\"\"\n",
    "    Process a chunk of ML predictions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    persons_data : list[dict[str, Any]]\n",
    "        List of person data dictionaries for prediction\n",
    "    chunk_id : int\n",
    "        Unique identifier for this chunk\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, Any]\n",
    "        Dictionary containing chunk processing results and metadata\n",
    "    \"\"\"\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Validate input data\n",
    "        multi_persons = MultiPersonsSchema(persons=persons_data)  # type: ignore\n",
    "        total_items = len(multi_persons.persons)\n",
    "\n",
    "        # Load model once for the entire chunk\n",
    "        model_dict_fp: Path = PACKAGE_PATH / \"models/model.pkl\"\n",
    "        with open(model_dict_fp, \"rb\") as f:\n",
    "            model_dict = joblib.load(f)\n",
    "\n",
    "        # Process predictions\n",
    "        prediction_results = []\n",
    "\n",
    "        for i, person in enumerate(multi_persons.persons):\n",
    "            # Update task progress\n",
    "            current_task.update_state(\n",
    "                state=\"PROGRESS\",\n",
    "                meta={\"current\": i + 1, \"total\": total_items, \"chunk_id\": chunk_id},\n",
    "            )\n",
    "\n",
    "            # Make individual prediction\n",
    "            result: ModelOutput = get_prediction(person, model_dict)\n",
    "            prediction_results.append(result.model_dump())\n",
    "\n",
    "        processing_time = time.time() - start_time\n",
    "\n",
    "        logger.info(f\"Processed chunk {chunk_id} with {total_items} predictions in {processing_time:.2f}s\")\n",
    "\n",
    "        return {\n",
    "            \"chunk_id\": chunk_id,\n",
    "            \"prediction_results\": prediction_results,\n",
    "            \"processing_time\": processing_time,\n",
    "            \"items_count\": total_items,\n",
    "            \"status\": \"success\",\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing prediction chunk {chunk_id}: {e}\")\n",
    "        raise self.retry(exc=e) from e\n",
    "\n",
    "\n",
    "@celery_app.task\n",
    "def combine_prediction_results(chunk_results: list[dict[str, Any]]) -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Combine results from multiple prediction chunks.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    chunk_results : list[dict[str, Any]]\n",
    "        List of chunk processing results\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, Any]\n",
    "        Dictionary containing combined prediction results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with get_db_session() as session:\n",
    "            # Sort chunks by chunk_id\n",
    "            sorted_results = sorted(chunk_results, key=lambda x: x[\"chunk_id\"])\n",
    "\n",
    "            # Combine all prediction results\n",
    "            combined_predictions = []\n",
    "            total_processing_time = 0\n",
    "            total_items = 0\n",
    "\n",
    "            for result in sorted_results:\n",
    "                combined_predictions.extend(result[\"prediction_results\"])\n",
    "                total_processing_time += result[\"processing_time\"]\n",
    "                total_items += result[\"items_count\"]\n",
    "\n",
    "            avg_processing_time = round((total_processing_time / len(sorted_results)), 2)\n",
    "\n",
    "            # Save to database\n",
    "            job_data = {\n",
    "                \"job_name\": \"batch_ml_prediction\",\n",
    "                \"input_data\": json.dumps({\"chunks\": len(sorted_results), \"total_items\": total_items}),\n",
    "                \"output_data\": json.dumps({\"predictions\": combined_predictions}),\n",
    "                \"processing_time\": avg_processing_time,\n",
    "                \"prediction_count\": total_items,\n",
    "                \"status\": \"completed\",\n",
    "                \"completed_at\": datetime.now(),\n",
    "            }\n",
    "\n",
    "            job = MLPredictionJob(**job_data)\n",
    "            session.add(job)\n",
    "            session.flush()\n",
    "\n",
    "            logger.info(f\"Combined {len(sorted_results)} chunks with {total_items} total predictions\")\n",
    "\n",
    "            return {\n",
    "                \"status\": \"completed\",\n",
    "                \"total_chunks\": len(sorted_results),\n",
    "                \"total_predictions\": total_items,\n",
    "                \"avg_processing_time\": avg_processing_time,\n",
    "                \"job_id\": job.id,\n",
    "                \"predictions\": combined_predictions,\n",
    "            }\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error combining prediction results: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "@celery_app.task\n",
    "def process_batch_predictions(persons_data: list[dict[str, Any]], chunk_size: int = 10) -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Process a large batch of ML predictions by splitting into chunks and using chord.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    persons_data : list[dict[str, Any]]\n",
    "        List of person data dictionaries for prediction\n",
    "    chunk_size : int, optional\n",
    "        Size of each processing chunk, by default 10\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, Any]\n",
    "        Dictionary containing batch processing dispatch information\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Split data into chunks\n",
    "        chunks = [persons_data[i : i + chunk_size] for i in range(0, len(persons_data), chunk_size)]\n",
    "\n",
    "        # Create a chord: process chunks in parallel, then combine results\n",
    "        job = chord(\n",
    "            group(process_prediction_chunk.s(chunk, i) for i, chunk in enumerate(chunks)),\n",
    "            combine_prediction_results.s(),\n",
    "        )\n",
    "\n",
    "        result = job.apply_async()\n",
    "\n",
    "        logger.info(f\"Dispatched batch prediction job with {len(persons_data)} items in {len(chunks)} chunks\")\n",
    "\n",
    "        return {\n",
    "            \"status\": \"dispatched\",\n",
    "            \"total_items\": len(persons_data),\n",
    "            \"chunks\": len(chunks),\n",
    "            \"chunk_size\": chunk_size,\n",
    "            \"chord_id\": result.id,\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error dispatching batch predictions: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "@celery_app.task(bind=True, base=BaseTask)\n",
    "def process_dlq_message(self, message_data: dict[str, Any]) -> dict[str, Any]:  # noqa: ANN001\n",
    "    \"\"\"\n",
    "    Process a message from the dead letter queue.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    message_data : dict[str, Any]\n",
    "        Message data from DLQ\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, Any]\n",
    "        Dictionary containing DLQ processing results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate the message data\n",
    "        if \"persons\" in message_data:\n",
    "            # Batch message\n",
    "            record = MultiPersonsSchema(**message_data)\n",
    "            message_type = \"batch\"\n",
    "            item_count = len(record.persons)\n",
    "        else:\n",
    "            # Single message\n",
    "            record = PersonSchema(**message_data)\n",
    "            message_type = \"single\"\n",
    "            item_count = 1\n",
    "\n",
    "        # Log DLQ message to database (you might want to create a DLQ table)\n",
    "        logger.warning(f\"Processing DLQ message: {message_type} with {item_count} items\")\n",
    "\n",
    "        # For now, just log the DLQ data - you can extend this to save to a DLQ table\n",
    "        with get_db_session() as session:\n",
    "            job_data = {\n",
    "                \"job_name\": f\"dlq_{message_type}_processing\",\n",
    "                \"input_data\": json.dumps(message_data),\n",
    "                \"output_data\": json.dumps({\"status\": \"dlq_processed\", \"message_type\": message_type}),\n",
    "                \"processing_time\": 0.0,\n",
    "                \"prediction_count\": 0,\n",
    "                \"status\": \"dlq_processed\",\n",
    "                \"completed_at\": datetime.now(),\n",
    "            }\n",
    "\n",
    "            job = MLPredictionJob(**job_data)\n",
    "            session.add(job)\n",
    "            session.flush()\n",
    "\n",
    "            logger.info(f\"DLQ message processed and logged with job_id: {job.id}\")\n",
    "\n",
    "            return {\n",
    "                \"status\": \"dlq_processed\",\n",
    "                \"message_type\": message_type,\n",
    "                \"item_count\": item_count,\n",
    "                \"job_id\": job.id,\n",
    "            }\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing DLQ message: {e}\")\n",
    "        raise self.retry(exc=e) from e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eaaad0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a769141e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "batch-process",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
